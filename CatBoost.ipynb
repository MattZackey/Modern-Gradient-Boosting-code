{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882af066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, plot_confusion_matrix, f1_score, accuracy_score, matthews_corrcoef\n",
    "from catboost import cv, Pool\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe05c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for performing cross-validation with CatBoost model.\n",
    "def catboost_tune_class(param_comb, X, y, num_iterations, colsample, class_imbal, learning_rate, boosting_type, score_function, categorical_feat, cv_metric):\n",
    "\n",
    "    param_comb = np.hstack((param_comb, np.zeros((param_comb.shape[0], 2))))\n",
    "    \n",
    "    #Creating dataset\n",
    "    ind_cat = X.dtypes == object\n",
    "    cat_feat = X.columns[ind_cat].tolist()\n",
    "    cat_dat = Pool(X, y, cat_features=cat_feat)\n",
    "\n",
    "    #Checking if class imbalance\n",
    "    if(class_imbal == True): \n",
    "        weight_pos = sum(y == 0)/sum(y == 1)\n",
    "    else: \n",
    "        weight_pos = 1\n",
    "\n",
    "    for i in range(param_comb.shape[0]):\n",
    "  \n",
    "        cats_params = {\n",
    "            'iterations' : num_iterations,\n",
    "            'learning_rate' : learning_rate,\n",
    "            'depth' : int(param_comb[i, 0]),\n",
    "            'rsm' : colsample,\n",
    "            'loss_function' : 'Logloss',\n",
    "            'leaf_estimation_iterations' : 1, \n",
    "            'leaf_estimation_method' : 'Newton', \n",
    "            'random_seed' : 63,\n",
    "            'verbose' : 10,\n",
    "            'metric_period' : 1,\n",
    "            'bagging_temperature' : 0.5,\n",
    "            'boosting_type' : boosting_type,\n",
    "            'simple_ctr' : 'BinarizedTargetMeanValue',\n",
    "            'bootstrap_type' : 'Bayesian',\n",
    "            'sampling_frequency' : 'PerTree',\n",
    "            'scale_pos_weight' : weight_pos,\n",
    "            'grow_policy' : 'SymmetricTree',\n",
    "            'score_function' : score_function,\n",
    "            'custom_loss' : cv_metric, \n",
    "            'thread_count' : 1,\n",
    "            }\n",
    "        \n",
    "        cat_cv = cat.cv(params = cats_params,\n",
    "                        dtrain = cat_dat,\n",
    "                        nfold = 5,\n",
    "                        stratified = True,\n",
    "                        partition_random_seed = 543,\n",
    "                        early_stopping_rounds = 200,\n",
    "                        verbose = False)\n",
    "        \n",
    "        if(cv_metric == 'AUC'):\n",
    "            num_tree = np.argmax(cat_cv.loc[:,'test-AUC-mean']) + 1 #number of trees\n",
    "            opt_val = max(cat_cv.loc[:,'test-AUC-mean'])\n",
    "        else:\n",
    "            num_tree = np.argmin(cat_cv.loc[:,'test-Logloss-mean']) + 1 #number of trees\n",
    "            opt_val = min(cat_cv.loc[:,'test-Logloss-mean'])\n",
    "\n",
    "        param_comb[i,1:3] = num_tree, opt_val\n",
    "        \n",
    "        print(i)\n",
    "    \n",
    "    return(param_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc308e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for fitting CatBoost model.\n",
    "def catboost_fit_class(param_opt, X, y, colsample, class_imbal, learning_rate, boosting_type, score_function, categorical_feat):\n",
    "\n",
    "    #Checking if class imbalance\n",
    "    if(class_imbal == True): \n",
    "        weight_pos = sum(y==0)/sum(y==1)\n",
    "    else: \n",
    "        weight_pos = 1\n",
    "    \n",
    "    clf_cat = cat.CatBoostClassifier(iterations = int(param_opt[1]),\n",
    "                                     learning_rate = learning_rate,\n",
    "                                     depth = int(param_opt[0]),\n",
    "                                     rsm = colsample,\n",
    "                                     loss_function = 'Logloss',\n",
    "                                     leaf_estimation_iterations = 1, \n",
    "                                     leaf_estimation_method = 'Newton', \n",
    "                                     random_seed = 63,\n",
    "                                     verbose = False,\n",
    "                                     metric_period = 1,\n",
    "                                     bagging_temperature = 1,\n",
    "                                     boosting_type = boosting_type,\n",
    "                                     simple_ctr = 'BinarizedTargetMeanValue',\n",
    "                                     bootstrap_type = 'Bayesian',\n",
    "                                     sampling_frequency = 'PerTree',\n",
    "                                     scale_pos_weight = weight_pos,\n",
    "                                     grow_policy = 'SymmetricTree',\n",
    "                                     score_function = score_function)\n",
    "\n",
    "    ind_cat = X.dtypes == object\n",
    "    cat_feat = X.columns[ind_cat].tolist()\n",
    "    clf_cat.fit(X, y, cat_features=cat_feat)\n",
    "    \n",
    "    return(clf_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46048613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating errors of models.\n",
    "def errors_model(mod, X_test, y_test):\n",
    "    \n",
    "    pred_class = mod.predict(X_test) #Class predictions\n",
    "    acc = accuracy_score(y_test, pred_class) #Accuracy\n",
    "    f1 = f1_score(y_test, pred_class) #F1 score \n",
    "    matt = matthews_corrcoef(y_test, pred_class) #Matthews Correlation Coefficient\n",
    "    pred_prob = mod.predict_proba(X_test)[:,1] #Probability predictions\n",
    "    auc = roc_auc_score(y_test, pred_prob) #AUC\n",
    "    errs_mod = [acc, f1, matt, auc]\n",
    "    return(errs_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc0dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree depth values considered.\n",
    "params_depth = np.array(range(1, 11)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No scientific notation.\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10291c",
   "metadata": {},
   "source": [
    "# AdaBoost Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c92a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset and setting up data. \n",
    "import pickle\n",
    "file_name = 'Overlap_data.pickle'\n",
    "file = open(file_name,'rb')\n",
    "Overlap_data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "X_train_over = Overlap_data['X_train']\n",
    "y_train_over = Overlap_data['y_train']\n",
    "X_test_over = Overlap_data['X_test']\n",
    "y_test_over = Overlap_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173decbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordered vs Plain mode of boosting.\n",
    "\n",
    "#Tuning parameter values for boosting mode = Plain.\n",
    "##########################################################################################################################\n",
    "cv_plain_over = catboost_tune_class(param_comb = params_depth, \n",
    "                                    X = pd.DataFrame(X_train_over), \n",
    "                                    y = y_train_over, \n",
    "                                    num_iterations = 10000, \n",
    "                                    colsample = 1, \n",
    "                                    class_imbal = False, \n",
    "                                    learning_rate = 0.05, \n",
    "                                    boosting_type = 'Plain',\n",
    "                                    categorical_feat = False,\n",
    "                                    cv_metric = 'Logloss',\n",
    "                                    score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Plain and calculating errors of model.\n",
    "##########################################################################################################################\n",
    "opt_ind_plain = np.argmin(cv_plain_over[:,2])\n",
    "\n",
    "catmod_plain_over = catboost_fit_class(param_opt = cv_plain_over[opt_ind_plain,0:5], \n",
    "                                     X = pd.DataFrame(X_train_over), \n",
    "                                     y = y_train_over,  \n",
    "                                     colsample = 1, \n",
    "                                     class_imbal = False, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     boosting_type = 'Plain', \n",
    "                                     categorical_feat = False,\n",
    "                                     score_function = 'Cosine')\n",
    "\n",
    "errs_plain_over = errors_model(mod = catmod_plain_over, \n",
    "                             X_test = X_test_over, \n",
    "                             y_test = y_test_over)\n",
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "#Tuning parameter values for boosting mode = Ordered.\n",
    "##########################################################################################################################\n",
    "cv_ordered_over = catboost_tune_class(param_comb = cv_plain_over[opt_ind_plain,0].reshape(-1,1), \n",
    "                                      X = pd.DataFrame(X_train_over), \n",
    "                                      y = y_train_over, \n",
    "                                      num_iterations = 10000, \n",
    "                                      colsample = 1, \n",
    "                                      class_imbal = False, \n",
    "                                      learning_rate = 0.05, \n",
    "                                      boosting_type = 'Ordered', \n",
    "                                      categorical_feat = False,\n",
    "                                      cv_metric = 'Logloss',\n",
    "                                      score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "\n",
    "#Fitting optimal model for boosting mode = Ordered and calculating errors.\n",
    "##########################################################################################################################\n",
    "opt_ind_ordered = np.argmin(cv_ordered_over[:,2])\n",
    "\n",
    "catmod_ordered_over = catboost_fit_class(param_opt = cv_ordered_over[opt_ind_ordered,0:5], \n",
    "                                         X = pd.DataFrame(X_train_over), \n",
    "                                         y = y_train_over, \n",
    "                                         colsample = 1, \n",
    "                                         class_imbal = False, \n",
    "                                         learning_rate = 0.05, \n",
    "                                         boosting_type = 'Ordered', \n",
    "                                         categorical_feat = False,\n",
    "                                         score_function = 'Cosine')\n",
    "\n",
    "#Calculating errors of model.\n",
    "errs_ordered_over = errors_model(mod = catmod_ordered_over, \n",
    "                                 X_test = X_test_over, \n",
    "                                 y_test = y_test_over)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors of the Plain and Ordered modes.\n",
    "test_err_plain = np.append(cv_plain_over[opt_ind_plain,[0,1]],errs_plain_over)\n",
    "test_err_ordered = np.append(cv_ordered_over[opt_ind_ordered,[0,1]],errs_ordered_over)\n",
    "test_err_over = np.row_stack((test_err_plain,test_err_ordered))\n",
    "np.round(test_err_over,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model with squared error loss.\n",
    "\n",
    "#Tuning number_of_trees values.\n",
    "##########################################################################################################################\n",
    "cv_l2_over = catboost_tune_class(param_comb = params_depth, \n",
    "                                    X = pd.DataFrame(X_train_over), \n",
    "                                    y = y_train_over, \n",
    "                                    num_iterations = 10000, \n",
    "                                    colsample = 1, \n",
    "                                    class_imbal = False, \n",
    "                                    learning_rate = 0.05, \n",
    "                                    boosting_type = 'Ordered',\n",
    "                                    categorical_feat = False,\n",
    "                                    cv_metric = 'Logloss',\n",
    "                                    score_function = 'L2')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model anc calculating errors.\n",
    "##########################################################################################################################\n",
    "opt_ind_l2 = np.argmin(cv_l2_over[:,2])\n",
    "\n",
    "catmod_l2_over = catboost_fit_class(param_opt = cv_l2_over[opt_ind_l2,0:5], \n",
    "                                    X = pd.DataFrame(X_train_over), \n",
    "                                    y = y_train_over,  \n",
    "                                    colsample = 1, \n",
    "                                    class_imbal = False, \n",
    "                                    learning_rate = 0.05, \n",
    "                                    boosting_type = 'Plain', \n",
    "                                    categorical_feat = False,\n",
    "                                    score_function = 'L2')\n",
    "\n",
    "errs_l2_over = errors_model(mod = catmod_l2_over, \n",
    "                            X_test = X_test_over, \n",
    "                            y_test = y_test_over)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf847e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors for boosting with Cosine and squared error loss.\n",
    "test_err_plain = np.append(cv_plain_over[opt_ind_plain,[0,1]],errs_plain_over)\n",
    "test_err_l2 = np.append(cv_l2_over[opt_ind_l2,[0,1]],errs_l2_over)\n",
    "test_err_over = np.row_stack((test_err_plain,test_err_l2))\n",
    "np.round(test_err_over,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc548f4",
   "metadata": {},
   "source": [
    "# Phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and setting up data\n",
    "file_path_ph = 'C:\\\\Users\\\\Matt\\\\Documents\\\\Python code thesis\\\\Datasets\\\\phoneme.csv'\n",
    "df_ph = pd.read_csv(file_path_ph)\n",
    "X_ph = df_ph.drop('target',axis=1).copy()\n",
    "y_ph = df_ph['target'].copy()\n",
    "X_train_ph, X_test_ph, y_train_ph, y_test_ph = train_test_split(X_ph, y_ph, random_state=65, stratify=y_ph, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordered vs Plain mode of boosting.\n",
    "\n",
    "#Tuning parameter values for boosting mode = Plain \n",
    "##########################################################################################################################\n",
    "cv_plain_ph = catboost_tune_class(param_comb = params_depth, \n",
    "                                  X = X_train_ph, \n",
    "                                  y = y_train_ph, \n",
    "                                  num_iterations = 10000, \n",
    "                                  colsample = 1, \n",
    "                                  class_imbal = True, \n",
    "                                  learning_rate = 0.05, \n",
    "                                  boosting_type = 'Plain', \n",
    "                                  categorical_feat = False,\n",
    "                                  cv_metric = 'AUC',\n",
    "                                  score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Plain and calculating errors of model.\n",
    "##########################################################################################################################\n",
    "opt_ind_plain = np.argmax(cv_plain_ph[:,2])\n",
    "\n",
    "catmod_plain_ph = catboost_fit_class(param_opt = cv_plain_ph[opt_ind_plain,0:5], \n",
    "                                     X = X_train_ph, \n",
    "                                     y = y_train_ph,  \n",
    "                                     colsample = 1, \n",
    "                                     class_imbal = True, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     boosting_type = 'Plain', \n",
    "                                     categorical_feat = False,\n",
    "                                     score_function = 'Cosine')\n",
    "\n",
    "errs_plain_ph = errors_model(mod = catmod_plain_ph, \n",
    "                             X_test = X_test_ph, \n",
    "                             y_test = y_test_ph)\n",
    "##########################################################################################################################\n",
    "\n",
    "#Tuning parameter values for boosting mode = Ordered.\n",
    "##########################################################################################################################\n",
    "cv_ordered_ph = catboost_tune_class(param_comb =  cv_plain_ph[opt_ind_plain,0].reshape(-1,1), \n",
    "                                    X = X_train_ph, \n",
    "                                    y = y_train_ph, \n",
    "                                    num_iterations = 10000, \n",
    "                                    colsample = 1, \n",
    "                                    class_imbal = True, \n",
    "                                    learning_rate = 0.05, \n",
    "                                    boosting_type = 'Ordered', \n",
    "                                    categorical_feat = False,\n",
    "                                    cv_metric = 'AUC',\n",
    "                                    score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Ordered and calculating errors of model.\n",
    "##########################################################################################################################\n",
    "opt_ind_ordered = np.argmax(cv_ordered_ph[:,2])\n",
    "\n",
    "catmod_ordered_ph = catboost_fit_class(param_opt = cv_ordered_ph[opt_ind_ordered,0:5], \n",
    "                                       X = X_train_ph, \n",
    "                                       y = y_train_ph, \n",
    "                                       colsample = 1, \n",
    "                                       class_imbal = True, \n",
    "                                       learning_rate = 0.05, \n",
    "                                       boosting_type = 'Ordered', \n",
    "                                       categorical_feat = False,\n",
    "                                       score_function = 'Cosine')\n",
    "\n",
    "errs_ordered_ph = errors_model(mod = catmod_ordered_ph, \n",
    "                               X_test = X_test_ph, \n",
    "                               y_test = y_test_ph)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors of the Plain and Ordered modes.\n",
    "test_err_plain = np.append(cv_plain_ph[opt_ind_plain,[0,1]],errs_plain_ph)\n",
    "test_err_ordered = np.append(cv_ordered_ph[opt_ind_ordered,[0,1]],errs_ordered_ph)\n",
    "test_err_ph = np.row_stack((test_err_plain,test_err_ordered))\n",
    "np.round(test_err_ph,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model with squared error loss\n",
    "\n",
    "#Tuning number_of_trees values\n",
    "##########################################################################################################################\n",
    "cv_l2_ph = catboost_tune_class(param_comb = params_depth, \n",
    "                               X = pd.DataFrame(X_train_ph), \n",
    "                               y = y_train_ph, \n",
    "                               num_iterations = 10000, \n",
    "                               colsample = 1, \n",
    "                               class_imbal = True, \n",
    "                               learning_rate = 0.05, \n",
    "                               boosting_type = 'Plain',\n",
    "                               categorical_feat = False,\n",
    "                               cv_metric = 'AUC',\n",
    "                               score_function = 'L2')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model and calculating errors \n",
    "##########################################################################################################################\n",
    "opt_ind_l2 = np.argmax(cv_l2_ph[:,2])\n",
    "\n",
    "catmod_l2_ph = catboost_fit_class(param_opt = cv_l2_ph[opt_ind_l2,0:5], \n",
    "                                  X = pd.DataFrame(X_train_ph), \n",
    "                                  y = y_train_ph,  \n",
    "                                  colsample = 1, \n",
    "                                  class_imbal = True, \n",
    "                                  learning_rate = 0.05, \n",
    "                                  boosting_type = 'Plain', \n",
    "                                  categorical_feat = False,\n",
    "                                  score_function = 'L2')\n",
    "\n",
    "errs_l2_ph = errors_model(mod = catmod_l2_ph, \n",
    "                            X_test = X_test_ph, \n",
    "                            y_test = y_test_ph)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors for boosting with Cosine and squared error loss.\n",
    "test_err_plain = np.append(cv_plain_ph[opt_ind_plain,[0,1]],errs_plain_ph)\n",
    "test_err_l2 = np.append(cv_l2_ph[opt_ind_l2,[0,1]],errs_l2_ph)\n",
    "test_err_ph = np.row_stack((test_err_plain,test_err_l2))\n",
    "np.round(test_err_ph,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00e478",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc4cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and setting up data.\n",
    "file_path = 'C:\\\\Users\\\\Matt\\\\Documents\\\\Python code thesis\\\\Datasets\\\\adult1.csv'\n",
    "df_adult1 = pd.read_csv(file_path,header=None)\n",
    "file_path = 'C:\\\\Users\\\\Matt\\\\Documents\\\\Python code thesis\\\\Datasets\\\\adult2.csv'\n",
    "df_adult2 = pd.read_csv(file_path,header=None)\n",
    "df_adult = pd.concat([df_adult1, df_adult2])\n",
    "df_adult.columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"martial-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"target\"]\n",
    "df_adult.replace(' ','',regex=True,inplace=True)\n",
    "df_adult['target'] = df_adult['target'].apply(lambda x: x.rstrip('.'))\n",
    "df_adult['target'] = df_adult['target'].apply(lambda x: 0 if x==\"<=50K\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370557d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training/Test splitt\n",
    "X_adult = df_adult.drop('target', axis = 1).copy()\n",
    "y_adult = df_adult['target'].copy()\n",
    "X_train_adult, X_test_adult, y_train_adult, y_test_adult = train_test_split(X_adult, y_adult, random_state=65, stratify=y_adult, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordered vs Plain mode of boosting.\n",
    "\n",
    "#Tuning parameters for boosting mode = Plain.\n",
    "##########################################################################################################################\n",
    "cv_plain_adult = catboost_tune_class(param_comb = params_depth, \n",
    "                                     X = X_train_adult, \n",
    "                                     y = y_train_adult,\n",
    "                                     num_iterations = 10000, \n",
    "                                     colsample = 1, \n",
    "                                     class_imbal = True, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     boosting_type = 'Plain', \n",
    "                                     categorical_feat = True,\n",
    "                                     cv_metric = 'AUC',\n",
    "                                     score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Plain and calculating errors. \n",
    "##########################################################################################################################\n",
    "opt_ind_plain = np.argmax(cv_plain_adult[:,2])\n",
    "\n",
    "catmod_plain_adult = catboost_fit_class(param_opt = cv_plain_adult[opt_ind_plain,:], \n",
    "                                     X = X_train_adult, \n",
    "                                     y = y_train_adult, \n",
    "                                     colsample = 1, \n",
    "                                     class_imbal = True, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     boosting_type = 'Plain', \n",
    "                                     categorical_feat = True,\n",
    "                                     score_function = 'Cosine')\n",
    "\n",
    "errs_plain_adult = errors_model(mod = catmod_plain_adult, \n",
    "                                X_test = X_test_adult, \n",
    "                                y_test = y_test_adult)\n",
    "##########################################################################################################################\n",
    "\n",
    "#Tuning parameter values for boosting mode = Ordered.\n",
    "##########################################################################################################################\n",
    "cv_ordered_adult = catboost_tune_class(param_comb = cv_plain_adult[opt_ind_plain,0].reshape(-1,1), \n",
    "                                       X = X_train_adult, \n",
    "                                       y = y_train_adult, \n",
    "                                       num_iterations = 10000, \n",
    "                                       colsample = 1, \n",
    "                                       class_imbal = True, \n",
    "                                       learning_rate = 0.05, \n",
    "                                       boosting_type = 'Ordered', \n",
    "                                       categorical_feat = True,\n",
    "                                       cv_metric = 'AUC',\n",
    "                                       score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Ordered and calculating errors.\n",
    "##########################################################################################################################\n",
    "opt_ind_ordered = np.argmax(cv_ordered_adult[:,2])\n",
    "\n",
    "catmod_ordered_adult = catboost_fit_class(param_opt = cv_ordered_adult[opt_ind_ordered,0:5], \n",
    "                                       X = X_train_adult, \n",
    "                                       y = y_train_adult, \n",
    "                                       colsample = 1, \n",
    "                                       class_imbal = True, \n",
    "                                       learning_rate = 0.05, \n",
    "                                       boosting_type = 'Ordered', \n",
    "                                       categorical_feat = True,\n",
    "                                       score_function = 'Cosine')\n",
    "\n",
    "errs_ordered_adult = errors_model(mod = catmod_ordered_adult, \n",
    "                             X_test = X_test_adult, \n",
    "                             y_test = y_test_adult)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eaaccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors of the Plain and Ordered modes.\n",
    "test_err_plain = np.append(cv_plain_adult[opt_ind_plain,[0,1]],errs_plain_adult)\n",
    "test_err_ordered = np.append(cv_ordered_adult[opt_ind_ordered,[0,1]],errs_ordered_adult)\n",
    "test_err_adult = np.row_stack((test_err_plain,test_err_ordered))\n",
    "np.round(test_err_adult,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d73379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model with squared error loss.\n",
    "\n",
    "#Tuning number_of_trees values.\n",
    "##########################################################################################################################\n",
    "cv_l2_adult = catboost_tune_class(param_comb = cv_plain_adult[opt_ind_plain,0].reshape(-1,1), \n",
    "                                  X = pd.DataFrame(X_train_adult), \n",
    "                                  y = y_train_adult, \n",
    "                                  num_iterations = 10000, \n",
    "                                  colsample = 1, \n",
    "                                  class_imbal = False, \n",
    "                                  learning_rate = 0.05, \n",
    "                                  boosting_type = 'Plain',\n",
    "                                  categorical_feat = True,\n",
    "                                  cv_metric = 'AUC',\n",
    "                                  score_function = 'L2')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model and calculating errors.\n",
    "##########################################################################################################################\n",
    "opt_ind_l2 = np.argmax(cv_l2_adult[:,2])\n",
    "\n",
    "catmod_l2_adult = catboost_fit_class(param_opt = cv_l2_adult[opt_ind_l2,0:5], \n",
    "                                  X = pd.DataFrame(X_train_adult), \n",
    "                                  y = y_train_adult,  \n",
    "                                  colsample = 1, \n",
    "                                  class_imbal = False, \n",
    "                                  learning_rate = 0.05, \n",
    "                                  boosting_type = 'Plain', \n",
    "                                  categorical_feat = True,\n",
    "                                  score_function = 'L2')\n",
    "\n",
    "errs_l2_adult = errors_model(mod = catmod_l2_adult, \n",
    "                            X_test = X_test_adult, \n",
    "                            y_test = y_test_adult)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors for boosting with Cosine and squared error loss.\n",
    "test_err_plain = np.append(cv_plain_adult[opt_ind_plain,[0,1]],errs_plain_adult)\n",
    "test_err_l2 = np.append(cv_l2_adult[opt_ind_l2,[0,1]],errs_l2_adult)\n",
    "test_err_adult = np.row_stack((test_err_plain,test_err_l2))\n",
    "np.round(test_err_adult,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f617c3",
   "metadata": {},
   "source": [
    "# Santander Customer Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c447e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "import pickle\n",
    "file_name = 'customersatformat.pickle'\n",
    "file = open(file_name,'rb')\n",
    "df_sat = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1530ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training/Test split\n",
    "X_sat = df_sat.drop('TARGET', axis = 1).copy()\n",
    "y_sat = df_sat['TARGET'].copy()\n",
    "X_train_sat, X_test_sat, y_train_sat, y_test_sat = train_test_split(X_sat, y_sat, random_state=71, stratify=y_sat, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beaa2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordered vs Plain mode of boosting.\n",
    "\n",
    "#Tuning parameters for boosting mode = Plain.\n",
    "##########################################################################################################################\n",
    "cv_plain_sat = catboost_tune_class(param_comb = params_depth, \n",
    "                                   X = X_train_sat, \n",
    "                                   y = y_train_sat, \n",
    "                                   num_iterations = 10000, \n",
    "                                   colsample = 0.3, \n",
    "                                   class_imbal = True, \n",
    "                                   learning_rate = 0.05, \n",
    "                                   boosting_type = 'Plain', \n",
    "                                   categorical_feat = False,\n",
    "                                   metric='AUC',\n",
    "                                   score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Plain and Calculating errors of model.\n",
    "##########################################################################################################################\n",
    "opt_ind_plain = np.argmax(cv_plain_sat[:,2])\n",
    "\n",
    "catmod_plain_sat = catboost_fit_class(param_opt = cv_plain_sat[opt_ind_plain,:], \n",
    "                                      X = X_train_sat, \n",
    "                                      y = y_train_sat,  \n",
    "                                      colsample = 0.3, \n",
    "                                      class_imbal = True, \n",
    "                                      learning_rate = 0.05, \n",
    "                                      boosting_type = 'Plain', \n",
    "                                      categorical_feat = True,\n",
    "                                      score_function = 'Cosine')\n",
    "\n",
    "errs_plain_sat = errors_model(mod = catmod_plain_sat, \n",
    "                              X_test = X_test_sat, \n",
    "                              y_test = y_test_sat)\n",
    "##########################################################################################################################\n",
    "\n",
    "#Tuning parameter values for boosting mode = Ordered.\n",
    "##########################################################################################################################\n",
    "cv_ordered_sat = catboost_tune_class(param_comb = cv_plain_sat[opt_ind_plain,0].reshape(-1,1), \n",
    "                                     X = X_train_sat, \n",
    "                                     y = y_train_sat, \n",
    "                                     num_iterations = 10000, \n",
    "                                     colsample = 0.3, \n",
    "                                     class_imbal = True, \n",
    "                                     learning_rate = 0.05, \n",
    "                                     boosting_type = 'Ordered', \n",
    "                                     categorical_feat = True,\n",
    "                                     cv_metric = 'AUC',\n",
    "                                     score_function = 'Cosine')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model for boosting mode = Ordered and calculating errors of model.\n",
    "##########################################################################################################################\n",
    "opt_ind_ordered = np.argmax(cv_ordered_sat[:,2])\n",
    "\n",
    "catmod_ordered_sat = catboost_fit_class(param_opt = cv_ordered_sat[opt_ind_ordered,:], \n",
    "                                        X = X_train_sat, \n",
    "                                        y = y_train_sat,  \n",
    "                                        colsample = 0.3, \n",
    "                                        class_imbal = True, \n",
    "                                        learning_rate = 0.05, \n",
    "                                        boosting_type = 'Ordered', \n",
    "                                        categorical_feat = True,\n",
    "                                        score_function = 'Cosine')\n",
    "\n",
    "errs_ordered_sat = errors_model(mod = catmod_ordered_sat, \n",
    "                                X_test = X_test_sat, \n",
    "                                y_test = y_test_sat)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50239a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors of the Plain and Ordered modes.\n",
    "test_err_plain = np.append(cv_plain_sat[opt_ind_plain,[0,1]],errs_plain_sat)\n",
    "test_err_ordered = np.append(cv_ordered_sat[opt_ind_ordered,[0,1]],errs_ordered_sat)\n",
    "test_err_sat = np.row_stack((test_err_plain,test_err_ordered))\n",
    "np.round(test_err_sat,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7629e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting model with squared error loss\n",
    "\n",
    "#Tuning number_of_trees values.\n",
    "##########################################################################################################################\n",
    "\n",
    "cv_l2_sat = catboost_tune_class(param_comb = params_depth, \n",
    "                                X = pd.DataFrame(X_train_sat), \n",
    "                                y = y_train_sat, \n",
    "                                num_iterations = 10000, \n",
    "                                colsample = 0.3, \n",
    "                                class_imbal = True, \n",
    "                                learning_rate = 0.05, \n",
    "                                boosting_type = 'Plain',\n",
    "                                categorical_feat = False,\n",
    "                                cv_metric = 'AUC',\n",
    "                                score_function = 'L2')\n",
    "##########################################################################################################################\n",
    "\n",
    "#Fitting optimal model and calculating errors.\n",
    "##########################################################################################################################\n",
    "opt_ind_l2 = np.argmax(cv_l2_sat[:,2])\n",
    "\n",
    "catmod_l2_sat = catboost_fit_class(param_opt = cv_l2_sat[opt_ind_l2,0:5], \n",
    "                                   X = pd.DataFrame(X_train_sat), \n",
    "                                   y = y_train_sat,  \n",
    "                                   colsample = 0.3, \n",
    "                                   class_imbal = True, \n",
    "                                   learning_rate = 0.05, \n",
    "                                   boosting_type = 'Plain', \n",
    "                                   categorical_feat = False,\n",
    "                                   score_function = 'L2')\n",
    "\n",
    "errs_l2_sat = errors_model(mod = catmod_l2_sat, \n",
    "                           X_test = X_test_sat, \n",
    "                           y_test = y_test_sat)\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e827dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test errors for boosting with Cosine and squared error loss.\n",
    "test_err_plain = np.append(cv_plain_sat[opt_ind_plain,[0,1]],errs_plain_sat)\n",
    "test_err_l2 = np.append(cv_l2_sat[opt_ind_l2,[0,1]],errs_l2_sat)\n",
    "test_err_sat = np.row_stack((test_err_plain,test_err_l2))\n",
    "np.round(test_err_sat,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
